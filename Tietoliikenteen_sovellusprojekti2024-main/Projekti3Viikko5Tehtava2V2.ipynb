{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HGpw0jrouK4m",
        "outputId": "d04ee9d0-9e0b-48be-d73e-f3f751b38e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Luokkien esiintymät:\n",
            " sensorvalue_d\n",
            "5.0    266\n",
            "6.0    242\n",
            "3.0    218\n",
            "2.0    217\n",
            "1.0    193\n",
            "4.0    189\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m24\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.1375 - loss: 1.8105 - val_accuracy: 0.1509 - val_loss: 1.8221\n",
            "Epoch 2/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1423 - loss: 1.7958 - val_accuracy: 0.1509 - val_loss: 1.8138\n",
            "Epoch 3/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1523 - loss: 1.7804 - val_accuracy: 0.1509 - val_loss: 1.8058\n",
            "Epoch 4/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1587 - loss: 1.7739 - val_accuracy: 0.1509 - val_loss: 1.7978\n",
            "Epoch 5/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1397 - loss: 1.7630 - val_accuracy: 0.1509 - val_loss: 1.7901\n",
            "Epoch 6/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1693 - loss: 1.7503 - val_accuracy: 0.1509 - val_loss: 1.7825\n",
            "Epoch 7/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1436 - loss: 1.7579 - val_accuracy: 0.1509 - val_loss: 1.7751\n",
            "Epoch 8/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1455 - loss: 1.7501 - val_accuracy: 0.1509 - val_loss: 1.7678\n",
            "Epoch 9/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1543 - loss: 1.7417 - val_accuracy: 0.1509 - val_loss: 1.7606\n",
            "Epoch 10/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1404 - loss: 1.7419 - val_accuracy: 0.1509 - val_loss: 1.7536\n",
            "Epoch 11/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1766 - loss: 1.7181 - val_accuracy: 0.3208 - val_loss: 1.7468\n",
            "Epoch 12/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3120 - loss: 1.7347 - val_accuracy: 0.3208 - val_loss: 1.7401\n",
            "Epoch 13/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3318 - loss: 1.7136 - val_accuracy: 0.3208 - val_loss: 1.7336\n",
            "Epoch 14/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3089 - loss: 1.7294 - val_accuracy: 0.3208 - val_loss: 1.7271\n",
            "Epoch 15/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3365 - loss: 1.7052 - val_accuracy: 0.3208 - val_loss: 1.7209\n",
            "Epoch 16/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3199 - loss: 1.7042 - val_accuracy: 0.3208 - val_loss: 1.7147\n",
            "Epoch 17/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3291 - loss: 1.6918 - val_accuracy: 0.3208 - val_loss: 1.7086\n",
            "Epoch 18/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3382 - loss: 1.6904 - val_accuracy: 0.4245 - val_loss: 1.7024\n",
            "Epoch 19/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4523 - loss: 1.6795 - val_accuracy: 0.4717 - val_loss: 1.6964\n",
            "Epoch 20/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4666 - loss: 1.6820 - val_accuracy: 0.4717 - val_loss: 1.6905\n",
            "Epoch 21/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4710 - loss: 1.6771 - val_accuracy: 0.4717 - val_loss: 1.6845\n",
            "Epoch 22/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4799 - loss: 1.6619 - val_accuracy: 0.4717 - val_loss: 1.6788\n",
            "Epoch 23/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4891 - loss: 1.6552 - val_accuracy: 0.4717 - val_loss: 1.6730\n",
            "Epoch 24/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4786 - loss: 1.6548 - val_accuracy: 0.4717 - val_loss: 1.6674\n",
            "Epoch 25/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4881 - loss: 1.6442 - val_accuracy: 0.4717 - val_loss: 1.6618\n",
            "Epoch 26/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4827 - loss: 1.6409 - val_accuracy: 0.4717 - val_loss: 1.6563\n",
            "Epoch 27/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5084 - loss: 1.6203 - val_accuracy: 0.4717 - val_loss: 1.6509\n",
            "Epoch 28/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4773 - loss: 1.6350 - val_accuracy: 0.4717 - val_loss: 1.6455\n",
            "Epoch 29/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4879 - loss: 1.6259 - val_accuracy: 0.4717 - val_loss: 1.6401\n",
            "Epoch 30/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4930 - loss: 1.6199 - val_accuracy: 0.4717 - val_loss: 1.6347\n",
            "Epoch 31/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4701 - loss: 1.6239 - val_accuracy: 0.4717 - val_loss: 1.6295\n",
            "Epoch 32/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4873 - loss: 1.6118 - val_accuracy: 0.4717 - val_loss: 1.6243\n",
            "Epoch 33/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4797 - loss: 1.6112 - val_accuracy: 0.4717 - val_loss: 1.6191\n",
            "Epoch 34/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4730 - loss: 1.6073 - val_accuracy: 0.4717 - val_loss: 1.6140\n",
            "Epoch 35/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4927 - loss: 1.5925 - val_accuracy: 0.4717 - val_loss: 1.6090\n",
            "Epoch 36/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4805 - loss: 1.5970 - val_accuracy: 0.4717 - val_loss: 1.6040\n",
            "Epoch 37/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4780 - loss: 1.5926 - val_accuracy: 0.4717 - val_loss: 1.5990\n",
            "Epoch 38/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4996 - loss: 1.5745 - val_accuracy: 0.4717 - val_loss: 1.5941\n",
            "Epoch 39/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4861 - loss: 1.5783 - val_accuracy: 0.4717 - val_loss: 1.5892\n",
            "Epoch 40/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4679 - loss: 1.5854 - val_accuracy: 0.4717 - val_loss: 1.5843\n",
            "Epoch 41/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4763 - loss: 1.5774 - val_accuracy: 0.4717 - val_loss: 1.5795\n",
            "Epoch 42/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4749 - loss: 1.5700 - val_accuracy: 0.4717 - val_loss: 1.5749\n",
            "Epoch 43/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4742 - loss: 1.5660 - val_accuracy: 0.4717 - val_loss: 1.5703\n",
            "Epoch 44/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5034 - loss: 1.5501 - val_accuracy: 0.5000 - val_loss: 1.5656\n",
            "Epoch 45/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5231 - loss: 1.5584 - val_accuracy: 0.6038 - val_loss: 1.5610\n",
            "Epoch 46/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6453 - loss: 1.5458 - val_accuracy: 0.6604 - val_loss: 1.5564\n",
            "Epoch 47/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6830 - loss: 1.5372 - val_accuracy: 0.6698 - val_loss: 1.5520\n",
            "Epoch 48/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6765 - loss: 1.5430 - val_accuracy: 0.6698 - val_loss: 1.5475\n",
            "Epoch 49/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6863 - loss: 1.5317 - val_accuracy: 0.6698 - val_loss: 1.5430\n",
            "Epoch 50/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6871 - loss: 1.5299 - val_accuracy: 0.6698 - val_loss: 1.5385\n",
            "Epoch 51/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6859 - loss: 1.5268 - val_accuracy: 0.6698 - val_loss: 1.5340\n",
            "Epoch 52/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6825 - loss: 1.5188 - val_accuracy: 0.6698 - val_loss: 1.5295\n",
            "Epoch 53/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6681 - loss: 1.5329 - val_accuracy: 0.6698 - val_loss: 1.5251\n",
            "Epoch 54/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6542 - loss: 1.5239 - val_accuracy: 0.6698 - val_loss: 1.5208\n",
            "Epoch 55/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6765 - loss: 1.5134 - val_accuracy: 0.6698 - val_loss: 1.5166\n",
            "Epoch 56/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6939 - loss: 1.5018 - val_accuracy: 0.6698 - val_loss: 1.5123\n",
            "Epoch 57/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6823 - loss: 1.4987 - val_accuracy: 0.6698 - val_loss: 1.5081\n",
            "Epoch 58/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6678 - loss: 1.5027 - val_accuracy: 0.6698 - val_loss: 1.5037\n",
            "Epoch 59/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6952 - loss: 1.4884 - val_accuracy: 0.6698 - val_loss: 1.4995\n",
            "Epoch 60/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6758 - loss: 1.4941 - val_accuracy: 0.6698 - val_loss: 1.4952\n",
            "Epoch 61/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6815 - loss: 1.4912 - val_accuracy: 0.6698 - val_loss: 1.4910\n",
            "Epoch 62/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6802 - loss: 1.4762 - val_accuracy: 0.6698 - val_loss: 1.4868\n",
            "Epoch 63/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6759 - loss: 1.4766 - val_accuracy: 0.6698 - val_loss: 1.4827\n",
            "Epoch 64/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6662 - loss: 1.4782 - val_accuracy: 0.6698 - val_loss: 1.4786\n",
            "Epoch 65/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6649 - loss: 1.4737 - val_accuracy: 0.6698 - val_loss: 1.4744\n",
            "Epoch 66/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6778 - loss: 1.4666 - val_accuracy: 0.6698 - val_loss: 1.4702\n",
            "Epoch 67/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6904 - loss: 1.4520 - val_accuracy: 0.6698 - val_loss: 1.4661\n",
            "Epoch 68/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6785 - loss: 1.4598 - val_accuracy: 0.6698 - val_loss: 1.4620\n",
            "Epoch 69/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6874 - loss: 1.4492 - val_accuracy: 0.6698 - val_loss: 1.4580\n",
            "Epoch 70/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6745 - loss: 1.4530 - val_accuracy: 0.6698 - val_loss: 1.4540\n",
            "Epoch 71/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6611 - loss: 1.4532 - val_accuracy: 0.6698 - val_loss: 1.4501\n",
            "Epoch 72/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6938 - loss: 1.4418 - val_accuracy: 0.6698 - val_loss: 1.4461\n",
            "Epoch 73/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6812 - loss: 1.4408 - val_accuracy: 0.6698 - val_loss: 1.4422\n",
            "Epoch 74/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6879 - loss: 1.4334 - val_accuracy: 0.6698 - val_loss: 1.4383\n",
            "Epoch 75/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6840 - loss: 1.4264 - val_accuracy: 0.6698 - val_loss: 1.4344\n",
            "Epoch 76/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6803 - loss: 1.4284 - val_accuracy: 0.6698 - val_loss: 1.4305\n",
            "Epoch 77/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6769 - loss: 1.4281 - val_accuracy: 0.6698 - val_loss: 1.4266\n",
            "Epoch 78/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6813 - loss: 1.4177 - val_accuracy: 0.6698 - val_loss: 1.4228\n",
            "Epoch 79/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6765 - loss: 1.4150 - val_accuracy: 0.6698 - val_loss: 1.4189\n",
            "Epoch 80/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6746 - loss: 1.4161 - val_accuracy: 0.6698 - val_loss: 1.4151\n",
            "Epoch 81/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6790 - loss: 1.4083 - val_accuracy: 0.6698 - val_loss: 1.4112\n",
            "Epoch 82/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6878 - loss: 1.4054 - val_accuracy: 0.6698 - val_loss: 1.4073\n",
            "Epoch 83/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6792 - loss: 1.4060 - val_accuracy: 0.6698 - val_loss: 1.4036\n",
            "Epoch 84/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6821 - loss: 1.3941 - val_accuracy: 0.6698 - val_loss: 1.3998\n",
            "Epoch 85/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6839 - loss: 1.3912 - val_accuracy: 0.6792 - val_loss: 1.3961\n",
            "Epoch 86/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 1.3953 - val_accuracy: 0.6792 - val_loss: 1.3922\n",
            "Epoch 87/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 1.3897 - val_accuracy: 0.7075 - val_loss: 1.3885\n",
            "Epoch 88/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7182 - loss: 1.3872 - val_accuracy: 0.7358 - val_loss: 1.3850\n",
            "Epoch 89/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 1.3747 - val_accuracy: 0.7736 - val_loss: 1.3813\n",
            "Epoch 90/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 1.3819 - val_accuracy: 0.7925 - val_loss: 1.3777\n",
            "Epoch 91/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7856 - loss: 1.3745 - val_accuracy: 0.7925 - val_loss: 1.3740\n",
            "Epoch 92/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8229 - loss: 1.3643 - val_accuracy: 0.7925 - val_loss: 1.3704\n",
            "Epoch 93/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 1.3604 - val_accuracy: 0.7925 - val_loss: 1.3667\n",
            "Epoch 94/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 1.3640 - val_accuracy: 0.7925 - val_loss: 1.3631\n",
            "Epoch 95/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 1.3569 - val_accuracy: 0.7925 - val_loss: 1.3594\n",
            "Epoch 96/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 1.3486 - val_accuracy: 0.8019 - val_loss: 1.3558\n",
            "Epoch 97/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 1.3454 - val_accuracy: 0.8019 - val_loss: 1.3523\n",
            "Epoch 98/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8592 - loss: 1.3431 - val_accuracy: 0.8019 - val_loss: 1.3487\n",
            "Epoch 99/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 1.3462 - val_accuracy: 0.8019 - val_loss: 1.3449\n",
            "Epoch 100/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8478 - loss: 1.3367 - val_accuracy: 0.8019 - val_loss: 1.3413\n",
            "Epoch 101/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 1.3291 - val_accuracy: 0.8019 - val_loss: 1.3379\n",
            "Epoch 102/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8469 - loss: 1.3338 - val_accuracy: 0.8019 - val_loss: 1.3344\n",
            "Epoch 103/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 1.3215 - val_accuracy: 0.8019 - val_loss: 1.3310\n",
            "Epoch 104/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 1.3158 - val_accuracy: 0.8019 - val_loss: 1.3275\n",
            "Epoch 105/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8529 - loss: 1.3207 - val_accuracy: 0.8208 - val_loss: 1.3240\n",
            "Epoch 106/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8712 - loss: 1.3156 - val_accuracy: 0.8679 - val_loss: 1.3206\n",
            "Epoch 107/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8836 - loss: 1.3173 - val_accuracy: 0.9340 - val_loss: 1.3172\n",
            "Epoch 108/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 1.3112 - val_accuracy: 0.9717 - val_loss: 1.3137\n",
            "Epoch 109/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9669 - loss: 1.3074 - val_accuracy: 0.9811 - val_loss: 1.3103\n",
            "Epoch 110/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 1.2965 - val_accuracy: 0.9811 - val_loss: 1.3070\n",
            "Epoch 111/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 1.2975 - val_accuracy: 1.0000 - val_loss: 1.3036\n",
            "Epoch 112/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 1.2959 - val_accuracy: 1.0000 - val_loss: 1.3002\n",
            "Epoch 113/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2966 - val_accuracy: 1.0000 - val_loss: 1.2969\n",
            "Epoch 114/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2889 - val_accuracy: 1.0000 - val_loss: 1.2934\n",
            "Epoch 115/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2850 - val_accuracy: 1.0000 - val_loss: 1.2900\n",
            "Epoch 116/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2812 - val_accuracy: 1.0000 - val_loss: 1.2867\n",
            "Epoch 117/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2832 - val_accuracy: 1.0000 - val_loss: 1.2833\n",
            "Epoch 118/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2771 - val_accuracy: 1.0000 - val_loss: 1.2800\n",
            "Epoch 119/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2802 - val_accuracy: 1.0000 - val_loss: 1.2767\n",
            "Epoch 120/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2699 - val_accuracy: 1.0000 - val_loss: 1.2735\n",
            "Epoch 121/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2667 - val_accuracy: 1.0000 - val_loss: 1.2703\n",
            "Epoch 122/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.2675 - val_accuracy: 1.0000 - val_loss: 1.2670\n",
            "Epoch 123/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2589 - val_accuracy: 1.0000 - val_loss: 1.2637\n",
            "Epoch 124/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.2656 - val_accuracy: 1.0000 - val_loss: 1.2604\n",
            "Epoch 125/125\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.2535 - val_accuracy: 1.0000 - val_loss: 1.2571\n",
            "Test loss: 1.2647408246994019\n",
            "Test accuracy: 1.0\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00        48\n",
            "           2       1.00      1.00      1.00        48\n",
            "           3       1.00      1.00      1.00        32\n",
            "           4       1.00      1.00      1.00        54\n",
            "           5       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00       265\n",
            "   macro avg       1.00      1.00      1.00       265\n",
            "weighted avg       1.00      1.00      1.00       265\n",
            "\n",
            "Confusion Matrix:\n",
            " [[33  0  0  0  0  0]\n",
            " [ 0 48  0  0  0  0]\n",
            " [ 0  0 48  0  0  0]\n",
            " [ 0  0  0 32  0  0]\n",
            " [ 0  0  0  0 54  0]\n",
            " [ 0  0  0  0  0 50]]\n",
            "Painojen ja biasin 0 muoto: (3, 6)\n",
            "\n",
            "Painojen ja biasin 1 muoto: (6,)\n",
            "\n",
            "Input data shape: 3\n",
            "Weights list length: 2\n",
            "\n",
            "Verkon ulostulo: (forward_propagation): [0.0, 0.0, nan, nan, 0.0, nan]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\n",
            "Ennuste (model.predict): [[0. 0. 0. 0. 0. 1.]]\n",
            "\n",
            "Ero (absoluuttinen ero result ja prediction välillä):\n",
            "Ero 1: 0.00000000\n",
            "Ero 2: 0.00000000\n",
            "Ero 3: nan\n",
            "Ero 4: nan\n",
            "Ero 5: 0.00000000\n",
            "Ero 6: nan\n",
            "\n",
            "Keskimääräinen ero:  nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-ee56beb09ec9>:115: RuntimeWarning: overflow encountered in scalar power\n",
            "  exp_values = [2.718 ** i for i in z]  # Eksponenttiarvot\n",
            "<ipython-input-1-ee56beb09ec9>:117: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return [exp_value / total for exp_value in exp_values]  # Jaa eksponenttiarvot kokonaisuudella\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpezlxmcww'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135414943138912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135414916719968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Ladataan data CSV-tiedostosta\n",
        "file_path = \"data_from_mysql_where_g160.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Suodatetaan pois kaikki rivit, joissa 'sensorvalue_d' on 0\n",
        "data_filtered = data[data['sensorvalue_d'] != 0]\n",
        "\n",
        "x_data = data_filtered[['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c']].values  # x, y, z\n",
        "y_data = data_filtered['sensorvalue_d'].values # suunta\n",
        "\n",
        "# Lasketaan luokkien esiintymät\n",
        "class_counts = data_filtered['sensorvalue_d'].value_counts()\n",
        "print(\"Luokkien esiintymät:\\n\", class_counts)\n",
        "\n",
        "# Skaalaus [0, 1] väliin ilman NumPy:n vektorilaskentaa\n",
        "def scale_to_unit_interval(data):\n",
        "    min_vals = [float('inf')] * len(data[0])\n",
        "    max_vals = [float('-inf')] * len(data[0])\n",
        "\n",
        "    for row in data:\n",
        "        for col_idx, value in enumerate(row):\n",
        "            if value < min_vals[col_idx]:\n",
        "                min_vals[col_idx] = value\n",
        "            if value > max_vals[col_idx]:\n",
        "                max_vals[col_idx] = value\n",
        "\n",
        "    scaled_data = []\n",
        "    for row in data:\n",
        "        scaled_row = []\n",
        "        for col_idx, value in enumerate(row):\n",
        "            range_val = max_vals[col_idx] - min_vals[col_idx]\n",
        "            if range_val == 0:\n",
        "                range_val = 1  # Vältetään nollalla jakamista\n",
        "            scaled_value = (value - min_vals[col_idx]) / range_val\n",
        "            scaled_row.append(scaled_value)\n",
        "        scaled_data.append(scaled_row)\n",
        "\n",
        "    return scaled_data\n",
        "\n",
        "# Skaalataan syötteet\n",
        "x_data_scaled = scale_to_unit_interval(x_data)\n",
        "\n",
        "# Suuntaa on 6 luokkaa\n",
        "num_classes = 6\n",
        "y_data = keras.utils.to_categorical(y_data - 1, num_classes)\n",
        "\n",
        "# Muutetaan x_train ja x_test NumPy-taulukoiksi\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(x_data_scaled), np.array(y_data), test_size=0.2, random_state=42)\n",
        "\n",
        "# Määritellään malli, jossa on vain yksi dense-kerros\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(x_train.shape[1],)),  # Syötemuoto (x, y, z)\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),  # Yksi tiheä kerros\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Koulutetaan mallia\n",
        "batch_size = 128\n",
        "epochs = 125\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Arvioidaan malli testidatalla\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Tallennetaan malli (painot ja rakenne)\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Ennusteet\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_classes, y_pred_classes))\n",
        "\n",
        "# Osa 2\n",
        "\n",
        "# Haetaan mallin painot\n",
        "weights = model.get_weights()\n",
        "\n",
        "# Painot ovat lista, jossa on numpy-taulukoita\n",
        "for idx, weight in enumerate(weights):\n",
        "    print(f\"Painojen ja biasin {idx} muoto: {weight.shape}\")\n",
        "    print(\"\")\n",
        "\n",
        "# Aktivointifunktio ReLU\n",
        "def relu(x):\n",
        "    if isinstance(x, list):  # Jos x on lista\n",
        "        return [max(0, val) for val in x]\n",
        "    return max(0, x)  # Jos x on yksittäinen arvo\n",
        "\n",
        "# Aktivointifunktio Softmax\n",
        "def softmax(z):\n",
        "    exp_values = [2.718 ** i for i in z]  # Eksponenttiarvot\n",
        "    total = sum(exp_values)  # Lasketaan summan eksponentit\n",
        "    return [exp_value / total for exp_value in exp_values]  # Jaa eksponenttiarvot kokonaisuudella\n",
        "\n",
        "# Syöte\n",
        "for i in range(len(data_filtered)):\n",
        "    # Haetaan kunkin rivin arvot\n",
        "    x = data_filtered['sensorvalue_a'].values[i]\n",
        "    y = data_filtered['sensorvalue_b'].values[i]\n",
        "    z = data_filtered['sensorvalue_c'].values[i]\n",
        "\n",
        "    # Muutetaan syöte oikeaan muotoon\n",
        "    input_data = [x, y, z]\n",
        "\n",
        "#print(\"Input data shape:\", input_data.shape)\n",
        "print(\"Input data shape:\", len(input_data))\n",
        "print(\"Weights list length:\", len(weights))\n",
        "# Oikeat painot ja biasit\n",
        "weights_0, bias_0 = weights[0], weights[1]\n",
        "\n",
        "\n",
        "# Etenee syötteestä piilokerrosten kautta ulostuloon\n",
        "def forward_propagation(input_data):\n",
        "    # Tiheä kerros (dense layer) 0\n",
        "    z0 = []\n",
        "    for k in range(len(weights_0[0])):  # Käydään läpi piilokerroksen neuronit\n",
        "        z0_value = sum(input_data[i] * weights_0[i][k] for i in range(len(input_data))) + bias_0[k]\n",
        "        z0.append(z0_value)\n",
        "    a0 = [relu(z) for z in z0]  # Aktivointi ReLU-funktiolla\n",
        "\n",
        "    # Ulostulokerros (softmax)\n",
        "    output = softmax(a0)  # Softmax aktivointi\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "# Asetetaan NumPy:n tulostustapa niin, että ei käytetä tieteellistä merkintää\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "\n",
        "# Lasketaan tulos syötteelle (x, y, z)\n",
        "result = forward_propagation(input_data)\n",
        "print(\"\\nVerkon ulostulo: (forward_propagation):\", result)\n",
        "\n",
        "# Oikea syötemuoto model.predict\n",
        "input_data = np.array([input_data])  # Muutetaan NumPy-taulukoksi\n",
        "\n",
        "# Lasketaan ennuste koulutetulla mallilla\n",
        "prediction = model.predict(input_data)\n",
        "print(\"\\nEnnuste (model.predict):\", prediction)\n",
        "\n",
        "# Lasketaan ero tulosten välillä\n",
        "result = result  # Varmistetaan, että result on lista\n",
        "prediction = prediction[0].tolist()  # Muutetaan prediction listaksi\n",
        "\n",
        "# Lasketaan ero\n",
        "difference = [abs(r - p) for r, p in zip(result, prediction)]  # Lasketaan itseisarvoero\n",
        "\n",
        "# Tulostetaan ero desimaaleina ilman tieteellistä muotoa\n",
        "print(\"\\nEro (absoluuttinen ero result ja prediction välillä):\")\n",
        "for i, diff in enumerate(difference):\n",
        "    print(f\"Ero {i+1}: {diff:.8f}\")  # Tulostetaan desimaalimuodossa, pyöristettynä 8 desimaaliin\n",
        "\n",
        "# Keskimääräinen ero\n",
        "mean_difference = sum(difference) / len(difference)\n",
        "# Tulostetaan keskimääräinen ero desimaaleina ilman tieteellistä muotoa\n",
        "print(\"\\nKeskimääräinen ero: \", f\"{mean_difference:.8f}\")\n",
        "\n",
        "# Tallennetaan painot ja biasit header-tiedostoon\n",
        "header_file = \"neuroverkonKertoimet2.h\"\n",
        "\n",
        "with open(header_file, \"w\") as f:\n",
        "    f.write(\"#ifndef NEUROVERKONKERTOIMET_H\\n\")\n",
        "    f.write(\"#define NEUROVERKONKERTOIMET_H\\n\\n\")\n",
        "\n",
        "    # Kirjoitetaan painot ja biasit jokaiselle kerrokselle\n",
        "    for idx, weight in enumerate(weights):\n",
        "        if len(weight.shape) == 2:  # Painot (matriisi)\n",
        "            f.write(f\"float weights_{idx}[{weight.shape[0]}][{weight.shape[1]}] = {{\\n\")\n",
        "            for row in weight:\n",
        "                f.write(\"    {\" + \", \".join(map(str, row)) + \"},\\n\")\n",
        "            f.write(\"};\\n\\n\")\n",
        "        elif len(weight.shape) == 1:  # Bias (vektori)\n",
        "            f.write(f\"float biases_{idx}[{weight.shape[0]}] = {{\")\n",
        "            f.write(\", \".join(map(str, weight)))\n",
        "            f.write(\"};\\n\\n\")\n",
        "\n",
        "    f.write(\"#endif // NEUROVERKONKERTOIMET_H\\n\")\n",
        "\n",
        "# Lataa malli\n",
        "model = tf.keras.models.load_model('my_model.keras')\n",
        "\n",
        "# Muunna TensorFlow Lite -malliksi\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Tallenna muunnos\n",
        "with open('oma_malli.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    }
  ]
}