{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HGpw0jrouK4m",
        "outputId": "e542a9b0-9894-4c87-f48d-16c8468caff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id            timestamp  groupid  from_mac  to_mac  sensorvalue_a  \\\n",
            "0  39  2024-11-14 12:30:54       16         0       0         1510.0   \n",
            "1  40  2024-11-14 12:30:54       16         0       0         1503.0   \n",
            "2  41  2024-11-14 12:30:54       16         0       0         1511.0   \n",
            "3  42  2024-11-14 12:30:55       16         0       0         1509.0   \n",
            "4  43  2024-11-14 12:30:56       16         0       0         1505.0   \n",
            "\n",
            "   sensorvalue_b  sensorvalue_c  sensorvalue_d  sensorvalue_e  sensorvalue_f  \n",
            "0         1405.0         1812.0            0.0            0.0              0  \n",
            "1         1413.0         1818.0            0.0            0.0              0  \n",
            "2         1416.0         1814.0            0.0            0.0              0  \n",
            "3         1412.0         1814.0            0.0            0.0              0  \n",
            "4         1410.0         1804.0            0.0            0.0              0  \n",
            "x_train shape: (2210, 3)\n",
            "x_test shape: (553, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_64\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_64\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_320 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_321 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_64 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_322 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_323 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_324 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m198\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_320 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_321 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_322 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_323 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_324 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,454\u001b[0m (173.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,454</span> (173.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,454\u001b[0m (173.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,454</span> (173.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.2251 - loss: 1.7627 - val_accuracy: 0.5249 - val_loss: 1.6338\n",
            "Epoch 2/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4789 - loss: 1.6095 - val_accuracy: 0.5249 - val_loss: 1.3612\n",
            "Epoch 3/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5339 - loss: 1.2982 - val_accuracy: 0.6199 - val_loss: 1.0630\n",
            "Epoch 4/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6170 - loss: 1.0528 - val_accuracy: 0.6109 - val_loss: 0.9119\n",
            "Epoch 5/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6526 - loss: 0.9154 - val_accuracy: 0.6199 - val_loss: 0.8436\n",
            "Epoch 6/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6356 - loss: 0.8706 - val_accuracy: 0.6742 - val_loss: 0.8183\n",
            "Epoch 7/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6389 - loss: 0.8613 - val_accuracy: 0.6606 - val_loss: 0.7976\n",
            "Epoch 8/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6468 - loss: 0.8263 - val_accuracy: 0.6923 - val_loss: 0.7878\n",
            "Epoch 9/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6311 - loss: 0.8195 - val_accuracy: 0.6833 - val_loss: 0.7799\n",
            "Epoch 10/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6541 - loss: 0.8310 - val_accuracy: 0.6018 - val_loss: 0.7933\n",
            "Epoch 11/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6634 - loss: 0.8090 - val_accuracy: 0.6109 - val_loss: 0.7952\n",
            "Epoch 12/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6353 - loss: 0.8216 - val_accuracy: 0.6109 - val_loss: 0.7950\n",
            "Epoch 13/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6442 - loss: 0.7949 - val_accuracy: 0.6018 - val_loss: 0.7963\n",
            "Epoch 14/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6115 - loss: 0.8341 - val_accuracy: 0.6516 - val_loss: 0.7812\n",
            "Test loss: 0.838559091091156\n",
            "Test accuracy: 0.6437612771987915\n",
            "Painojen ja biasin 0 muoto: (3, 256)\n",
            "Painojen ja biasin 1 muoto: (256,)\n",
            "Painojen ja biasin 2 muoto: (256, 128)\n",
            "Painojen ja biasin 3 muoto: (128,)\n",
            "Painojen ja biasin 4 muoto: (128, 64)\n",
            "Painojen ja biasin 5 muoto: (64,)\n",
            "Painojen ja biasin 6 muoto: (64, 32)\n",
            "Painojen ja biasin 7 muoto: (32,)\n",
            "Painojen ja biasin 8 muoto: (32, 6)\n",
            "Painojen ja biasin 9 muoto: (6,)\n",
            "Input data shape: (1, 3)\n",
            "Input data scaled shape: (1, 3)\n",
            "\n",
            "Verkon ulostulo: (forward_propagation): [0.035115 0.503212 0.022592 0.00591  0.429353 0.003819]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\n",
            "Ennuste (model.predict): [[0.035106 0.503227 0.022585 0.005908 0.429358 0.003817]]\n",
            "\n",
            "Ero (absoluuttinen ero result ja prediction välillä): [0.000009 0.000015 0.000007 0.000002 0.000005 0.000002]\n",
            "\n",
            "Keskimääräinen ero:  6.8134395e-06\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras import layers, models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import files\n",
        "import math\n",
        "\n",
        "# Esimerkki\n",
        "'''\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "'''\n",
        "\n",
        "# Ladataan data CSV-tiedostosta\n",
        "file_path = \"data_from_mysql_where_g16.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Tarkastetaan datan rakenne\n",
        "print(data.head())\n",
        "\n",
        "# Suodatetaan pois kaikki rivit, joissa 'sensorvalue_d' on 0\n",
        "data_filtered = data[data['sensorvalue_d'] != 0]\n",
        "\n",
        "x_data = data_filtered[['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c']].values  # x, y, z\n",
        "y_data = data_filtered['sensorvalue_d'].values # suunta\n",
        "\n",
        "# Skaalaus [0, 1] väliin\n",
        "def scale_to_unit_interval(data):\n",
        "    min_vals = np.min(data, axis=0)  # Minimiarvot sarakkeittain\n",
        "    max_vals = np.max(data, axis=0)  # Maksimiarvot sarakkeittain\n",
        "    # Varmistetaan, ettei ole nollalla jakamista\n",
        "    ranges = max_vals - min_vals\n",
        "    ranges[ranges == 0] = 1  # Jos max == min, käytetään 1:stä\n",
        "\n",
        "    return (data - min_vals) / ranges  # Skaalaus [0, 1] väliin\n",
        "\n",
        "# Skaalataan syötteet\n",
        "x_data_scaled = scale_to_unit_interval(x_data)\n",
        "\n",
        "# Skaalataan syötteet [0, 1] väliin käyttäen StandardScaler\n",
        "#scaler = StandardScaler()\n",
        "#x_data = scaler.fit_transform(x_data.astype('float32'))\n",
        "\n",
        "# Suuntaa on 6 luokkaa\n",
        "num_classes = 6\n",
        "y_data = keras.utils.to_categorical(y_data - 1, num_classes)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data_scaled, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "\n",
        "# Määritellään malli\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(x_train.shape[1],)),  # Syötemuoto (x, y, z)\n",
        "        layers.Dense(256, activation=\"relu\"),  # Ensimmäinen tiheä kerros\n",
        "        layers.Dropout(0.2),  # Dropout, jotta ylikoulutus ei tapahdu\n",
        "        layers.Dense(128, activation=\"relu\"),  # Toinen tiheä kerros\n",
        "        layers.LeakyReLU(negative_slope=0.2),  # Vaihtoehto ReLU:lle\n",
        "        layers.Dense(64, activation=\"relu\"),  # Kolmas tiheä kerros\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),  # Lopullinen luokittelukerros\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Koulutetaan mallia\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Arvioidaan malli testidatalla\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Tallennetaan malli (painot ja rakenne)\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Osa 2\n",
        "\n",
        "# Haetaan mallin painot\n",
        "weights = model.get_weights()\n",
        "\n",
        "# Painot ovat lista, jossa on numpy-taulukoita\n",
        "for idx, weight in enumerate(weights):\n",
        "    print(f\"Painojen ja biasin {idx} muoto: {weight.shape}\")\n",
        "    #print(f\"Painot ja bias {idx}:\", weight)\n",
        "\n",
        "# Aktivointifunktiot\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)  # ReLU-funktio\n",
        "\n",
        "'''\n",
        "def softmax(x):\n",
        "    exp_values = np.exp(x - np.max(x))  # Stabiili softmax\n",
        "    return exp_values / exp_values.sum(axis=-1, keepdims=True)\n",
        "'''\n",
        "'''\n",
        "# Softmax ilman NumPytä\n",
        "def softmax(x):\n",
        "    max_val = max(x)  # Löydetään suurin arvo numeron stabiliteetin vuoksi\n",
        "    exp_values = [math.exp(i - max_val) for i in x]  # Lasketaan eksponentit ilman NumPytä\n",
        "    total = sum(exp_values)  # Lasketaan summa ilman NumPytä\n",
        "    return [i / total for i in exp_values]  # Normalisoidaan ilman NumPytä\n",
        "'''\n",
        "\n",
        "# Aktivointifunktio Softmax\n",
        "def softmax(z):\n",
        "    exp_values = [2.718 ** i for i in z]  # Eksponenttiarvot\n",
        "    total = sum(exp_values)  # Lasketaan summan eksponentit\n",
        "    return [exp_value / total for exp_value in exp_values]  # Jaa eksponenttiarvot kokonaisuudella\n",
        "\n",
        "# Syöte\n",
        "for i in range(len(data_filtered)):\n",
        "    # Haetaan kunkin rivin arvot\n",
        "    x = data_filtered['sensorvalue_a'].values[i]\n",
        "    y = data_filtered['sensorvalue_b'].values[i]\n",
        "    z = data_filtered['sensorvalue_c'].values[i]\n",
        "\n",
        "    # Muutetaan syöte oikeaan muotoon\n",
        "    input_data = np.array([x, y, z]).reshape(1, -1)  # Muutetaan muotoon (1, 3)\n",
        "\n",
        "#x = data_filtered['sensorvalue_a'].values[0]  # Ensimmäinen arvo sarakkeesta x\n",
        "#y = data_filtered['sensorvalue_b'].values[0]  # Ensimmäinen arvo sarakkeesta y\n",
        "#z = data_filtered['sensorvalue_c'].values[0]  # Ensimmäinen arvo sarakkeesta z\n",
        "\n",
        "#input_data = np.array([x, y, z]).reshape(1, -1)  # Muutetaan muotoon (1, 3)\n",
        "\n",
        "print(\"Input data shape:\", input_data.shape)\n",
        "\n",
        "# Skaalaus [0, 1] väliin\n",
        "def scale(data):\n",
        "    min_vals = np.min(data, axis=0)  # Minimiarvot sarakkeittain\n",
        "    max_vals = np.max(data, axis=0)  # Maksimiarvot sarakkeittain\n",
        "     # Varmistetaan, ettei ole nollalla jakamista\n",
        "    ranges = max_vals - min_vals\n",
        "    ranges[ranges == 0] = 1  # Jos max == min, käytetään 1:stä\n",
        "\n",
        "    return (data - min_vals) / ranges  # Skaalaus [0, 1] väliin\n",
        "\n",
        "# Skaalataan syöte\n",
        "input_data_scaled = scale(input_data.astype('float32'))\n",
        "\n",
        "# Varmistetaan, että data on skaalattu oikein\n",
        "#scaler = StandardScaler()\n",
        "#input_data_scaled = scaler.fit_transform(input_data.astype('float32'))\n",
        "\n",
        "print(\"Input data scaled shape:\", input_data_scaled.shape)\n",
        "\n",
        "# Oikeat painot ja biasit\n",
        "weights_0, bias_0 = weights[0], weights[1]\n",
        "weights_1, bias_1 = weights[2], weights[3]\n",
        "weights_2, bias_2 = weights[4], weights[5]\n",
        "weights_3, bias_3 = weights[6], weights[7]\n",
        "weights_4, bias_4 = weights[8], weights[9]\n",
        "\n",
        "'''\n",
        "# Etenee syötteestä piilokerrosten kautta ulostuloon (numpy)\n",
        "def forward_propagation(input_data):\n",
        "    # Piilokerros 1\n",
        "    z0 = np.dot(input_data, weights_0) + bias_0\n",
        "    a0 = relu(z0)  # Aktivointi\n",
        "\n",
        "    # Piilokerros 2\n",
        "    z1 = np.dot(a0, weights_1) + bias_1\n",
        "    a1 = relu(z1)  # Aktivointi\n",
        "\n",
        "    # Piilokerros 3\n",
        "    z2 = np.dot(a1, weights_2) + bias_2\n",
        "    a2 = relu(z2)  # Aktivointi\n",
        "\n",
        "    # Piilokerros 4\n",
        "    z3 = np.dot(a2, weights_3) + bias_3\n",
        "    a3 = relu(z3)  # Aktivointi\n",
        "\n",
        "    # Ulostulokerros\n",
        "    z4 = np.dot(a3, weights_4) + bias_4\n",
        "    output = softmax(z4)  # Softmax aktivointi\n",
        "\n",
        "    return output\n",
        "'''\n",
        "'''\n",
        "# Etenee syötteestä piilokerrosten kautta ulostuloon (yhdellä arvolla)\n",
        "def forward_propagation(input_data):\n",
        "    # Piilokerros 1\n",
        "    z0 = [sum(i * j for i, j in zip(input_data[0], weights_0[:, k])) + bias_0[k] for k in range(weights_0.shape[1])]\n",
        "    a0 = [relu(z) for z in z0]  # Aktivointi\n",
        "\n",
        "    # Piilokerros 2\n",
        "    z1 = [sum(i * j for i, j in zip(a0, weights_1[:, k])) + bias_1[k] for k in range(weights_1.shape[1])]\n",
        "    a1 = [relu(z) for z in z1]  # Aktivointi\n",
        "\n",
        "    # Piilokerros 3\n",
        "    z2 = [sum(i * j for i, j in zip(a1, weights_2[:, k])) + bias_2[k] for k in range(weights_2.shape[1])]\n",
        "    a2 = [relu(z) for z in z2]  # Aktivointi\n",
        "\n",
        "    # Piilokerros 4\n",
        "    z3 = [sum(i * j for i, j in zip(a2, weights_3[:, k])) + bias_3[k] for k in range(weights_3.shape[1])]\n",
        "    a3 = [relu(z) for z in z3]  # Aktivointi\n",
        "\n",
        "    # Ulostulokerros\n",
        "    z4 = [sum(i * j for i, j in zip(a3, weights_4[:, k])) + bias_4[k] for k in range(weights_4.shape[1])]\n",
        "    output = softmax(z4)  # Softmax aktivointi\n",
        "\n",
        "    return output\n",
        "'''\n",
        "\n",
        "#Etenee syötteestä piilokerrosten kautta ulostuloon\n",
        "def forward_propagation(input_data):\n",
        "    # Piilokerros 1\n",
        "    z0 = []\n",
        "    for k in range(len(weights_0[0])):  # Käydään läpi piilokerroksen neuronit\n",
        "        z0_value = sum(input_data_scaled[i] * weights_0[i][k] for i in range(len(input_data_scaled))) + bias_0[k]\n",
        "        z0.append(z0_value)\n",
        "    a0 = [relu(z) for z in z0]  # Aktivointi\n",
        "\n",
        "    # Piilokerros 2\n",
        "    z1 = []\n",
        "    for k in range(len(weights_1[0])):\n",
        "        z1_value = sum(a0[i] * weights_1[i][k] for i in range(len(a0))) + bias_1[k]\n",
        "        z1.append(z1_value)\n",
        "    a1 = [relu(z) for z in z1]  # Aktivointi\n",
        "\n",
        "    # Piilokerros 3\n",
        "    z2 = []\n",
        "    for k in range(len(weights_2[0])):\n",
        "        z2_value = sum(a1[i] * weights_2[i][k] for i in range(len(a1))) + bias_2[k]\n",
        "        z2.append(z2_value)\n",
        "    a2 = [relu(z) for z in z2]  # Aktivointi\n",
        "\n",
        "    # Piilokerros 4\n",
        "    z3 = []\n",
        "    for k in range(len(weights_3[0])):\n",
        "        z3_value = sum(a2[i] * weights_3[i][k] for i in range(len(a2))) + bias_3[k]\n",
        "        z3.append(z3_value)\n",
        "    a3 = [relu(z) for z in z3]  # Aktivointi\n",
        "\n",
        "    # Ulostulokerros\n",
        "    z4 = []\n",
        "    for k in range(len(weights_4[0])):\n",
        "        z4_value = sum(a3[i] * weights_4[i][k] for i in range(len(a3))) + bias_4[k]\n",
        "        z4.append(z4_value)\n",
        "    output = softmax(z4)  # Softmax aktivointi\n",
        "\n",
        "    # Muotoillaan tulos muotoon (1, 6) ja pyöristetään arvoja samalla tarkkuudella kuin model.predict\n",
        "    output = np.array(output)  # Varmistetaan, että output on numpy-taulukko\n",
        "    output = np.round(output, 6).reshape(1, -1)  # Muotoillaan ja pyöristetään\n",
        "\n",
        "    # Tulostetaan arvot, jotka ovat indekseissä 0, 3, 6, 9, jne.\n",
        "    selected_values = output[0][::3]  # Valitaan arvot, jotka ovat paikoissa 0, 3, 6, 9 jne.\n",
        "\n",
        "    return selected_values\n",
        "\n",
        "    #return output\n",
        "\n",
        "# Asetetaan NumPy:n tulostustapa niin, että ei käytetä tieteellistä merkintää\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "\n",
        "# Lasketaan tulos syötteelle (x, y, z)\n",
        "result = forward_propagation(input_data_scaled)\n",
        "print(\"\\nVerkon ulostulo: (forward_propagation):\", result)\n",
        "\n",
        "# Lasketaan ennuste koulutetulla mallilla\n",
        "prediction = model.predict(input_data_scaled)\n",
        "print(\"\\nEnnuste (model.predict):\", prediction)\n",
        "\n",
        "# Lasketaan ero tulosten välillä\n",
        "# Ensimmäinen vaihe on varmistaa, että molemmat result ja prediction ovat numpy-taulukkoja\n",
        "result = np.array(result).reshape(-1)  # Muutetaan result tasaiseksi taulukoksi\n",
        "prediction = np.array(prediction).reshape(-1)  # Muutetaan prediction tasaiseksi taulukoksi\n",
        "\n",
        "# Lasketaan ero\n",
        "difference = np.abs(result - prediction)  # Lasketaan itseisarvoero\n",
        "\n",
        "# Tulostetaan ero\n",
        "print(\"\\nEro (absoluuttinen ero result ja prediction välillä):\", difference)\n",
        "\n",
        "# Keskimääräinen ero\n",
        "mean_difference = np.mean(difference)\n",
        "print(\"\\nKeskimääräinen ero: \", mean_difference)\n",
        "\n",
        "# Tallennetaan painot ja biasit header-tiedostoon\n",
        "header_file = \"neuroverkonKertoimet.h\"\n",
        "\n",
        "with open(header_file, \"w\") as f:\n",
        "    f.write(\"#ifndef NEUROVERKONKERTOIMET_H\\n\")\n",
        "    f.write(\"#define NEUROVERKONKERTOIMET_H\\n\\n\")\n",
        "\n",
        "    # Kirjoitetaan painot ja biasit jokaiselle kerrokselle\n",
        "    for idx, weight in enumerate(weights):\n",
        "        if len(weight.shape) == 2:  # Painot (matriisi)\n",
        "            f.write(f\"float weights_{idx}[{weight.shape[0]}][{weight.shape[1]}] = {{\\n\")\n",
        "            for row in weight:\n",
        "                f.write(\"    {\" + \", \".join(map(str, row)) + \"},\\n\")\n",
        "            f.write(\"};\\n\\n\")\n",
        "        elif len(weight.shape) == 1:  # Bias (vektori)\n",
        "            f.write(f\"float biases_{idx}[{weight.shape[0]}] = {{\")\n",
        "            f.write(\", \".join(map(str, weight)))\n",
        "            f.write(\"};\\n\\n\")\n",
        "\n",
        "    f.write(\"#endif // NEUROVERKONKERTOIMET_H\\n\")"
      ]
    }
  ]
}
