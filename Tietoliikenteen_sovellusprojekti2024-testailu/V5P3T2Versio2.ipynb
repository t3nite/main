{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HGpw0jrouK4m",
        "outputId": "d74e884f-677a-4d46-9b34-00f48aaba4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id            timestamp  groupid  from_mac  to_mac  sensorvalue_a  \\\n",
            "0  39  2024-11-14 12:30:54       16         0       0         1510.0   \n",
            "1  40  2024-11-14 12:30:54       16         0       0         1503.0   \n",
            "2  41  2024-11-14 12:30:54       16         0       0         1511.0   \n",
            "3  42  2024-11-14 12:30:55       16         0       0         1509.0   \n",
            "4  43  2024-11-14 12:30:56       16         0       0         1505.0   \n",
            "\n",
            "   sensorvalue_b  sensorvalue_c  sensorvalue_d  sensorvalue_e  sensorvalue_f  \n",
            "0         1405.0         1812.0            0.0            0.0              0  \n",
            "1         1413.0         1818.0            0.0            0.0              0  \n",
            "2         1416.0         1814.0            0.0            0.0              0  \n",
            "3         1412.0         1814.0            0.0            0.0              0  \n",
            "4         1410.0         1804.0            0.0            0.0              0  \n",
            "x_train shape: (2210, 3)\n",
            "x_test shape: (553, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_12 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m198\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,454\u001b[0m (173.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,454</span> (173.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,454\u001b[0m (173.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,454</span> (173.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - accuracy: 0.4211 - loss: 1.6923 - val_accuracy: 0.6063 - val_loss: 1.2619\n",
            "Epoch 2/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6210 - loss: 1.1517 - val_accuracy: 0.6154 - val_loss: 0.8753\n",
            "Epoch 3/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6262 - loss: 0.8981 - val_accuracy: 0.6923 - val_loss: 0.8158\n",
            "Epoch 4/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.8071 - val_accuracy: 0.6606 - val_loss: 0.7979\n",
            "Epoch 5/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6689 - loss: 0.7691 - val_accuracy: 0.6516 - val_loss: 0.7790\n",
            "Epoch 6/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 0.8130 - val_accuracy: 0.6742 - val_loss: 0.7758\n",
            "Epoch 7/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6357 - loss: 0.8133 - val_accuracy: 0.6923 - val_loss: 0.7654\n",
            "Epoch 8/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.7765 - val_accuracy: 0.6652 - val_loss: 0.7643\n",
            "Epoch 9/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6864 - loss: 0.7680 - val_accuracy: 0.6606 - val_loss: 0.7563\n",
            "Epoch 10/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6734 - loss: 0.7810 - val_accuracy: 0.7240 - val_loss: 0.7298\n",
            "Epoch 11/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7204 - loss: 0.7466 - val_accuracy: 0.7149 - val_loss: 0.7292\n",
            "Epoch 12/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7051 - loss: 0.7519 - val_accuracy: 0.6787 - val_loss: 0.7287\n",
            "Epoch 13/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6846 - loss: 0.7142 - val_accuracy: 0.7014 - val_loss: 0.7057\n",
            "Epoch 14/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6957 - loss: 0.7448 - val_accuracy: 0.7195 - val_loss: 0.7171\n",
            "Epoch 15/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6890 - loss: 0.7588 - val_accuracy: 0.7014 - val_loss: 0.7326\n",
            "Epoch 16/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7172 - loss: 0.7181 - val_accuracy: 0.7240 - val_loss: 0.7042\n",
            "Epoch 17/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7272 - loss: 0.7085 - val_accuracy: 0.7240 - val_loss: 0.6777\n",
            "Epoch 18/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.6916 - val_accuracy: 0.7195 - val_loss: 0.6604\n",
            "Epoch 19/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.6647 - val_accuracy: 0.7195 - val_loss: 0.6639\n",
            "Epoch 20/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.6576 - val_accuracy: 0.7376 - val_loss: 0.6582\n",
            "Epoch 21/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7440 - loss: 0.6671 - val_accuracy: 0.7421 - val_loss: 0.6482\n",
            "Epoch 22/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.6495 - val_accuracy: 0.7421 - val_loss: 0.6560\n",
            "Epoch 23/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.6439 - val_accuracy: 0.7421 - val_loss: 0.6464\n",
            "Epoch 24/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.6227 - val_accuracy: 0.7466 - val_loss: 0.6286\n",
            "Epoch 25/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7595 - loss: 0.6485 - val_accuracy: 0.7557 - val_loss: 0.6390\n",
            "Epoch 26/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7707 - loss: 0.6085 - val_accuracy: 0.7466 - val_loss: 0.6184\n",
            "Epoch 27/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.6160 - val_accuracy: 0.7511 - val_loss: 0.6751\n",
            "Epoch 28/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7586 - loss: 0.6471 - val_accuracy: 0.7692 - val_loss: 0.6302\n",
            "Epoch 29/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.6230 - val_accuracy: 0.7511 - val_loss: 0.6429\n",
            "Epoch 30/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.5920 - val_accuracy: 0.7557 - val_loss: 0.6180\n",
            "Epoch 31/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.5929 - val_accuracy: 0.7647 - val_loss: 0.6243\n",
            "Epoch 32/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5895 - val_accuracy: 0.7557 - val_loss: 0.6041\n",
            "Epoch 33/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.5818 - val_accuracy: 0.7692 - val_loss: 0.6148\n",
            "Epoch 34/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.5586 - val_accuracy: 0.7511 - val_loss: 0.5958\n",
            "Epoch 35/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.5806 - val_accuracy: 0.7692 - val_loss: 0.5792\n",
            "Epoch 36/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.5694 - val_accuracy: 0.7421 - val_loss: 0.6002\n",
            "Epoch 37/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.5699 - val_accuracy: 0.7647 - val_loss: 0.5809\n",
            "Epoch 38/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7890 - loss: 0.5457 - val_accuracy: 0.7738 - val_loss: 0.5704\n",
            "Epoch 39/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.5649 - val_accuracy: 0.7873 - val_loss: 0.5538\n",
            "Epoch 40/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.5524 - val_accuracy: 0.7783 - val_loss: 0.5594\n",
            "Epoch 41/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7890 - loss: 0.5460 - val_accuracy: 0.7738 - val_loss: 0.5901\n",
            "Epoch 42/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.5258 - val_accuracy: 0.7873 - val_loss: 0.5642\n",
            "Epoch 43/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.5429 - val_accuracy: 0.7738 - val_loss: 0.5642\n",
            "Epoch 44/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.5154 - val_accuracy: 0.7692 - val_loss: 0.5563\n",
            "Test loss: 0.5454260110855103\n",
            "Test accuracy: 0.7920433878898621\n",
            "Painojen ja biasin 0 muoto: (3, 256)\n",
            "Painojen ja biasin 1 muoto: (256,)\n",
            "Painojen ja biasin 2 muoto: (256, 128)\n",
            "Painojen ja biasin 3 muoto: (128,)\n",
            "Painojen ja biasin 4 muoto: (128, 64)\n",
            "Painojen ja biasin 5 muoto: (64,)\n",
            "Painojen ja biasin 6 muoto: (64, 32)\n",
            "Painojen ja biasin 7 muoto: (32,)\n",
            "Painojen ja biasin 8 muoto: (32, 6)\n",
            "Painojen ja biasin 9 muoto: (6,)\n",
            "Verkon ulostulo: [[0. 0. 1. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras import layers, models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import files\n",
        "\n",
        "# Esimerkki\n",
        "'''\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "'''\n",
        "\n",
        "# Ladataan data CSV-tiedostosta\n",
        "file_path = \"data_from_mysql_where_g16.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Tarkastetaan datan rakenne\n",
        "print(data.head())\n",
        "\n",
        "# Suodatetaan pois kaikki rivit, joissa 'sensorvalue_d' on 0\n",
        "data_filtered = data[data['sensorvalue_d'] != 0]\n",
        "\n",
        "x_data = data_filtered[['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c']].values  # x, y, z\n",
        "y_data = data_filtered['sensorvalue_d'].values # suunta\n",
        "\n",
        "# Skaalataan syötteet [0, 1] väliin käyttäen StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_data = scaler.fit_transform(x_data.astype('float32'))\n",
        "\n",
        "# Suuntaa on 6 luokkaa\n",
        "num_classes = 6\n",
        "y_data = keras.utils.to_categorical(y_data - 1, num_classes)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "\n",
        "# Määritellään malli\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(x_train.shape[1],)),  # Syötemuoto (x, y, z)\n",
        "        layers.Dense(256, activation=\"relu\"),  # Ensimmäinen tiheä kerros\n",
        "        layers.Dropout(0.2),  # Dropout, jotta ylikoulutus ei tapahdu\n",
        "        layers.Dense(128, activation=\"relu\"),  # Toinen tiheä kerros\n",
        "        layers.LeakyReLU(negative_slope=0.2),  # Vaihtoehto ReLU:lle\n",
        "        layers.Dense(64, activation=\"relu\"),  # Kolmas tiheä kerros\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),  # Lopullinen luokittelukerros\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Koulutetaan mallia\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Arvioidaan malli testidatalla\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Tallennetaan malli (painot ja rakenne)\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Osa 2\n",
        "\n",
        "# Haetaan mallin painot\n",
        "weights = model.get_weights()\n",
        "\n",
        "# Painot ovat lista, jossa on numpy-taulukoita\n",
        "for idx, weight in enumerate(weights):\n",
        "    print(f\"Painojen ja biasin {idx} muoto: {weight.shape}\")\n",
        "    #print(f\"Painot ja bias {idx}:\", weight)\n",
        "\n",
        "# Aktivointifunktiot\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)  # ReLU-funktio\n",
        "\n",
        "def softmax(x):\n",
        "    exp_values = np.exp(x - np.max(x))  # Stabiili softmax\n",
        "    return exp_values / exp_values.sum(axis=-1, keepdims=True)\n",
        "\n",
        "# Syöte\n",
        "x = data_filtered['sensorvalue_a'].values\n",
        "y = data_filtered['sensorvalue_b'].values\n",
        "z = data_filtered['sensorvalue_c'].values\n",
        "\n",
        "# esim.\n",
        "#x = 1200\n",
        "#y = 1500\n",
        "#z = 1800\n",
        "\n",
        "\n",
        "# Esimerkiksi käytetään vain ensimmäistä riviä syötteeksi:\n",
        "input_data = np.array([x[0], y[0], z[0]]).reshape(1, -1)  # Muutetaan muotoon (1, 3)\n",
        "\n",
        "#input_data = np.array([x, y, z]).reshape(1, -1)  # Muutetaan syöte oikeaan muotoon  # X, Y, Z syötteet\n",
        "\n",
        "# Esimerkki: painot ja biasit manuaalisesti määriteltynä\n",
        "weights_0 = np.random.randn(3, 256)  # Painot piilokerrokselle 1 (3 syötettä, 256 neuronin koko)\n",
        "bias_0 = np.random.randn(256)       # Bias piilokerrokselle 1\n",
        "\n",
        "weights_1 = np.random.randn(256, 128)  # Painot piilokerrokselle 2 (256 -> 128)\n",
        "bias_1 = np.random.randn(128)         # Bias piilokerrokselle 2\n",
        "\n",
        "weights_2 = np.random.randn(128, 64)   # Painot piilokerrokselle 3 (128 -> 64)\n",
        "bias_2 = np.random.randn(64)          # Bias piilokerrokselle 3\n",
        "\n",
        "weights_3 = np.random.randn(64, 32)    # Painot piilokerrokselle 4 (64 -> 32)\n",
        "bias_3 = np.random.randn(32)          # Bias piilokerrokselle 4\n",
        "\n",
        "weights_4 = np.random.randn(32, 6)     # Painot ulostulokerrokselle (32 -> 6)\n",
        "bias_4 = np.random.randn(6)           # Bias ulostulokerrokselle\n",
        "\n",
        "# Etenee syötteestä piilokerrosten kautta ulostuloon\n",
        "def forward_propagation(input_data):\n",
        "    # Piilokerros 1\n",
        "    z0 = np.dot(input_data, weights_0) + bias_0\n",
        "    a0 = relu(z0)  # Aktivointi\n",
        "\n",
        "    # Piilokerros 2\n",
        "    z1 = np.dot(a0, weights_1) + bias_1\n",
        "    a1 = relu(z1)  # Aktivointi\n",
        "\n",
        "    # Piilokerros 3\n",
        "    z2 = np.dot(a1, weights_2) + bias_2\n",
        "    a2 = relu(z2)  # Aktivointi\n",
        "\n",
        "    # Piilokerros 4\n",
        "    z3 = np.dot(a2, weights_3) + bias_3\n",
        "    a3 = relu(z3)  # Aktivointi\n",
        "\n",
        "    # Ulostulokerros\n",
        "    z4 = np.dot(a3, weights_4) + bias_4\n",
        "    output = softmax(z4)  # Softmax aktivointi\n",
        "\n",
        "    return output\n",
        "\n",
        "# Laske tulos syötteelle (x, y, z)\n",
        "result = forward_propagation(input_data)\n",
        "\n",
        "# Tulosta tulos\n",
        "print(\"Verkon ulostulo:\", result)\n",
        "\n",
        "# Tallenna painot ja biasit header-tiedostoon\n",
        "header_file = \"neuroverkonKertoimet.h\"\n",
        "\n",
        "with open(header_file, \"w\") as f:\n",
        "    f.write(\"#ifndef NEUROVERKONKERTOIMET_H\\n\")\n",
        "    f.write(\"#define NEUROVERKONKERTOIMET_H\\n\\n\")\n",
        "\n",
        "    # Kirjoita painot ja biasit jokaiselle kerrokselle\n",
        "    for idx, weight in enumerate(weights):\n",
        "        if len(weight.shape) == 2:  # Painot (matriisi)\n",
        "            f.write(f\"float weights_{idx}[{weight.shape[0]}][{weight.shape[1]}] = {{\\n\")\n",
        "            for row in weight:\n",
        "                f.write(\"    {\" + \", \".join(map(str, row)) + \"},\\n\")\n",
        "            f.write(\"};\\n\\n\")\n",
        "        elif len(weight.shape) == 1:  # Bias (vektori)\n",
        "            f.write(f\"float biases_{idx}[{weight.shape[0]}] = {{\")\n",
        "            f.write(\", \".join(map(str, weight)))\n",
        "            f.write(\"};\\n\\n\")\n",
        "\n",
        "    f.write(\"#endif // NEUROVERKONKERTOIMET_H\\n\")\n",
        "\n"
      ]
    }
  ]
}
